% Encoding: UTF-8

@Article{Hershey2015,
  author        = {John R. Hershey and Zhuo Chen and Jonathan Le Roux and Shinji Watanabe},
  title         = {{Deep clustering: Discriminative embeddings for segmentation and separation}},
  year          = {2015},
  archiveprefix = {arXiv},
  eprint        = {1508.04306},
  file          = {:Hershey2015.pdf:PDF},
  keywords      = {cs.NE, cs.LG, stat.ML, rank1},
  primaryclass  = {cs.NE},
  timestamp     = {Mon, 13 Aug 2018 16:46:39 +0200},
}

@InProceedings{Huang2014,
  author    = {P. Huang and M. Kim and M. Hasegawa-Johnson and P. Smaragdis},
  title     = {Deep learning for monaural speech separation},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2014},
  pages     = {1562--1566},
  month     = may,
  doi       = {10.1109/ICASSP.2014.6853860},
  file      = {:Huang2014.pdf:PDF;:Huang2014.pdf:PDF},
  issn      = {1520-6149},
  keywords  = {learning (artificial intelligence), recurrent neural nets, signal reconstruction, source separation, speech processing, monaural speech separation, monaural source separation, deep learning models, deep neural networks, recurrent neural networks, masking layer, reconstruction constraint, TIMIT speech corpus, NMF models, SDRs, SARs, Training, Time-frequency analysis, Artificial neural networks, Speech, Source separation, Discrete Fourier transforms, Monaural Source Separation, Time-Frequency Masking, Deep Learning, rank4},
}

@Article{Wang2018b,
  author   = {D. Wang and J. Chen},
  title    = {Supervised Speech Separation Based on Deep Learning: An Overview},
  journal  = {IEEE/ACM Transactions on Acoustics, Speech, and Signal Processing},
  year     = {2018},
  volume   = {26},
  number   = {10},
  pages    = {1702-1726},
  month    = {Oct},
  abstract = {Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This paper provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then, we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multitalker separation), and speech dereverberation, as well as multimicrophone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source.},
  doi      = {10.1109/TASLP.2018.2842159},
  file     = {:Wang2018b.pdf:PDF},
  keywords = {learning (artificial intelligence);speech enhancement;speech intelligibility;supervised speech separation;deep learning;target speech;supervised learning problem;supervised separation algorithms;speech enhancement;speech-nonspeech separation;multitalker separation;speech dereverberation;Speech enhancement;Interference;Noise measurement;Training;Supervised learning;Task analysis;Seech separation;speaker separation;speech enhancement;supervised speech separation;deep learning;deep neural networks;speech dereverberation;time-frequency masking;array separation;beamforming, rank5},
}

@Article{Cherry1953,
  author   = {Cherry,E. Colin},
  title    = {Some Experiments on the Recognition of Speech, with One and with Two Ears},
  journal  = {The Journal of the Acoustical Society of America},
  year     = {1953},
  volume   = {25},
  number   = {5},
  pages    = {975-979},
  doi      = {10.1121/1.1907229},
  file     = {:Cherry1953.pdf:PDF},
  keywords = {rank2},
}

@Article{Virtanen2007,
  author    = {Tuomas Virtanen},
  title     = {Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria},
  journal   = {{IEEE} Transactions on Audio, Speech and Language Processing},
  year      = {2007},
  volume    = {15},
  number    = {3},
  pages     = {1066--1074},
  month     = {mar},
  doi       = {10.1109/tasl.2006.885253},
  file      = {:Virtanen2007.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Vincent2006,
  author    = {E. Vincent and R. Gribonval and C. Fevotte},
  title     = {Performance measurement in blind audio source separation},
  journal   = {{IEEE} Transactions on Audio, Speech and Language Processing},
  year      = {2006},
  volume    = {14},
  number    = {4},
  pages     = {1462--1469},
  month     = {jul},
  comment   = {BSS Toolkit},
  doi       = {10.1109/tsa.2005.858005},
  file      = {:Vincent2006.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Wang2018,
  author    = {Zhong-Qiu Wang and Jonathan Le Roux and John R. Hershey},
  title     = {Alternative Objective Functions for Deep Clustering},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2018},
  month     = {apr},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp.2018.8462507},
}

@InProceedings{Isik2016,
  author    = {Yusuf Isik and Jonathan Le Roux and Zhuo Chen and Shinji Watanabe and John R. Hershey},
  title     = {Single-Channel Multi-Speaker Separation Using Deep Clustering},
  booktitle = {Interspeech},
  year      = {2016},
  month     = {sep},
  publisher = {{ISCA}},
  doi       = {10.21437/interspeech.2016-1176},
  file      = {:1176.PDF:PDF},
}

@Article{Stoeter2018,
  author        = {{St{\"o}ter}, Fabian-Robert and {Liutkus}, Antoine and {Ito}, Nobutaka},
  title         = {{The 2018 Signal Separation Evaluation Campaign}},
  year          = {2018},
  month         = {Apr},
  archiveprefix = {arXiv},
  eprint        = {1804.06267},
  primaryclass  = {eess.AS},
}

@InProceedings{Adiga2016,
  author    = {M. Tejus Adiga and Rekha Bhandarkar},
  title     = {Improving single frequency filtering based Voice Activity Detection ({VAD}) using spectral subtraction based noise cancellation},
  booktitle = {2016 International Conference on Signal Processing, Communication, Power and Embedded System ({SCOPES})},
  year      = {2016},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.1109/scopes.2016.7955823},
}

@InProceedings{Hershey2016,
  author    = {John R. Hershey and Zhuo Chen and Jonathan Le Roux and Shinji Watanabe},
  title     = {Deep clustering: Discriminative embeddings for segmentation and separation},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2016},
  month     = {mar},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp.2016.7471631},
  file      = {:Hershey2016.pdf:PDF},
}

@Book{Lyons1997,
  title     = {Understanding Digital Signal Processing},
  publisher = {Addison Wesley Pub. Co},
  year      = {1997},
  author    = {Richard G. Lyons},
  edition   = {1st},
  isbn      = {9780201634679},
  file      = {:Lyons1997.djvu:Djvu},
}

@Article{Cooley1965,
  author    = {James W. Cooley and John W. Tukey},
  title     = {An algorithm for the machine calculation of complex Fourier series},
  journal   = {Mathematics of Computation},
  year      = {1965},
  volume    = {19},
  number    = {90},
  pages     = {297--297},
  month     = {may},
  doi       = {10.1090/s0025-5718-1965-0178586-1},
  publisher = {American Mathematical Society ({AMS})},
}

@Article{Emiya2011,
  author    = {Valentin Emiya and Emmanuel Vincent and Niklas Harlander and Volker Hohmann},
  title     = {Subjective and Objective Quality Assessment of Audio Source Separation},
  journal   = {{IEEE} Transactions on Audio, Speech, and Language Processing},
  year      = {2011},
  volume    = {19},
  number    = {7},
  pages     = {2046--2057},
  month     = {sep},
  comment   = {PEASS Toolkit},
  doi       = {10.1109/tasl.2011.2109381},
  file      = {:Emiya2011.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Book{Oppenheim1999,
  title     = {Discrete-time Signal Processing},
  publisher = {Prentice-Hall, Inc.},
  year      = {1999},
  author    = {Oppenheim, Alan V. and Schafer, Ronald W. and Buck, John R.},
  edition   = {2},
  isbn      = {0-13-754920-2},
  file      = {:Oppenheim1999.djvu:Djvu},
}

@InCollection{Smith2011,
  author    = {Julius O. Smith},
  title     = {Overlap-Add STFT Processing},
  booktitle = {Spectral Audio Signal Processing},
  year      = {2011},
  url       = {https://ccrma.stanford.edu/~jos/sasp/Overlap_Add_Decomposition.html},
  urldate   = {2019-07-16},
}

@Misc{Heinzel2002,
  author = {G. Heinzel and A. Ruediger and R. Schilling},
  title  = {{Spectrum and spectral density estimation by the Discrete Fourier transform (DFT), including a comprehensive list of window functions and some new at-top windows.}},
  month  = feb,
  year   = {2002},
  file   = {:Heinzel2002.pdf:PDF},
}

@Book{Oppenheim2014,
  title     = {Discrete-Time Signal Processing},
  publisher = {Pearson Education},
  year      = {2014},
  author    = {Oppenheim, Alan V. and Schafer, Ronald W.},
  edition   = {3rd},
  isbn      = {1-292-02572-7, 978-1-292-02572-8},
  file      = {:Oppenheim2014.pdf:PDF},
}

@Book{Oliphant2006,
  title     = {A guide to NumPy},
  publisher = {Trelgol Publishing},
  year      = {2006},
  author    = {Oliphant, Travis E},
  volume    = {1},
}

@Article{Harris1978,
  author    = {F.J. Harris},
  title     = {On the use of windows for harmonic analysis with the discrete Fourier transform},
  journal   = {Proceedings of the {IEEE}},
  year      = {1978},
  volume    = {66},
  number    = {1},
  pages     = {51--83},
  doi       = {10.1109/proc.1978.10837},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Rosen2013,
  author    = {Stuart Rosen and Pamela Souza and Caroline Ekelund and Arooj A Majeed},
  title     = {Listening to speech in a background of other talkers: Effects of talker number and noise vocoding},
  journal   = {The Journal of the Acoustical Society of America},
  year      = {2013},
  volume    = {133},
  number    = {4},
  pages     = {2431--2443},
  month     = {apr},
  doi       = {10.1121/1.4794379},
  file      = {:Rosen2013.pdf:PDF},
  publisher = {Acoustical Society of America ({ASA})},
}

@Article{Miller1947,
  author        = {George A. Miller},
  title         = {The masking of speech.},
  journal       = {Psychological Bulletin},
  year          = {1947},
  volume        = {44},
  number        = {2},
  pages         = {105--129},
  __markedentry = {[max:]},
  doi           = {10.1037/h0055960},
  file          = {:Miller1947.pdf:PDF},
  publisher     = {American Psychological Association ({APA})},
}

@Book{Wang2006,
  title     = {Computational Auditory Scene Analysis: Principles, Algorithms, and Applications},
  publisher = {Wiley},
  year      = {2006},
  author    = {Wang, D.L. and Brown, G.J.},
  isbn      = {9780471741091},
  file      = {:Wang2006.djvu:Djvu},
  lccn      = {2007275811},
}

@Article{Festen1990,
  author    = {Joost M. Festen and Reinier Plomp},
  title     = {Effects of fluctuating noise and interfering speech on the speech-reception threshold for impaired and normal hearing},
  journal   = {The Journal of the Acoustical Society of America},
  year      = {1990},
  volume    = {88},
  number    = {4},
  pages     = {1725--1736},
  month     = {oct},
  doi       = {10.1121/1.400247},
  file      = {:Festen1990.pdf:PDF},
  publisher = {Acoustical Society of America ({ASA})},
}

@Article{Lee1999,
  author    = {Daniel D. Lee and H. Sebastian Seung},
  title     = {Learning the parts of objects by non-negative matrix factorization},
  journal   = {Nature},
  year      = {1999},
  volume    = {401},
  number    = {6755},
  pages     = {788--791},
  month     = {oct},
  doi       = {10.1038/44565},
  publisher = {Springer Nature},
}

@Conference{Dubnov2002,
  author    = {Dubnov, Shlomo},
  title     = {Extracting Sound Objects by Independent Subspace Analysis},
  booktitle = {Audio Engineering Society Conference: 22nd International Conference: Virtual, Synthetic, and Entertainment Audio},
  year      = {2002},
  month     = {Jun},
}

@InProceedings{Casey2000,
  author    = {Michael A. Casey and Alex Westner},
  title     = {Separation of Mixed Audio Sources By Independent Subspace Analysis},
  booktitle = {ICMC},
  year      = {2000},
}

@InBook{Wang2005,
  pages     = {181--197},
  title     = {{On Ideal Binary Mask As the Computational Goal of Auditory Scene Analysis}},
  publisher = {Springer},
  year      = {2005},
  author    = {Wang, DeLiang},
  editor    = {Divenyi, Pierre},
  isbn      = {978-0-387-22794-8},
  abstract  = {In his famous treatise of computational vision, Marr (1982) makes a compelling argument for separating different levels of analysis in order to understand complex information processing. In particular, the computational theory level, concerned with the goal of computation and general processing strategy, must be separated from the algorithm level, or the separation of what from how. This chapter is an attempt at a computational-theory analysis of auditory scene analysis, where the main task is to understand the character of the CASA problem.},
  booktitle = {Speech Separation by Humans and Machines},
  doi       = {10.1007/0-387-22794-6_12},
}

@InProceedings{Schuller2010,
  author    = {Bjorn Schuller and Felix Weninger and Martin Wollmer and Yang Sun and Gerhard Rigoll},
  title     = {Non-negative matrix factorization as noise-robust feature extractor for speech recognition},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2010},
  month     = {mar},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp.2010.5495567},
  file      = {:Schuller2010.pdf:PDF},
}

@Article{Qian2018,
  author   = {Qian, Yan-min and Weng, Chao and Chang, Xuan-kai and Wang, Shuai and Yu, Dong},
  title    = {Past review, current progress, and challenges ahead on the cocktail party problem},
  journal  = {Frontiers of Information Technology {\&} Electronic Engineering},
  year     = {2018},
  volume   = {19},
  number   = {1},
  pages    = {40--63},
  month    = {Jan},
  issn     = {2095-9230},
  abstract = {The cocktail party problem, i.e., tracing and recognizing the speech of a specific speaker when multiple speakers talk simultaneously, is one of the critical problems yet to be solved to enable the wide application of automatic speech recognition (ASR) systems. In this overview paper, we review the techniques proposed in the last two decades in attacking this problem. We focus our discussions on the speech separation problem given its central role in the cocktail party environment, and describe the conventional single-channel techniques such as computational auditory scene analysis (CASA), non-negative matrix factorization (NMF) and generative models, the conventional multi-channel techniques such as beamforming and multi-channel blind source separation, and the newly developed deep learning-based techniques, such as deep clustering (DPCL), the deep attractor network (DANet), and permutation invariant training (PIT). We also present techniques developed to improve ASR accuracy and speaker identification in the cocktail party environment. We argue effectively exploiting information in the microphone array, the acoustic training set, and the language itself using a more powerful model. Better optimization objective and techniques will be the approach to solving the cocktail party problem.},
  day      = {01},
  doi      = {10.1631/FITEE.1700814},
  file     = {:Qian2018.pdf:PDF},
}

@Article{Hu2007,
  author    = {Yi Hu and Philipos C. Loizou},
  title     = {Subjective comparison and evaluation of speech enhancement algorithms},
  journal   = {Speech Communication},
  year      = {2007},
  volume    = {49},
  number    = {7-8},
  pages     = {588--601},
  month     = {jul},
  doi       = {10.1016/j.specom.2006.12.006},
  file      = {:Hu2007.pdf:PDF},
  publisher = {Elsevier {BV}},
}

@Article{Ephraim1985,
  author    = {Y. Ephraim and D. Malah},
  title     = {Speech enhancement using a minimum mean-square error log-spectral amplitude estimator},
  journal   = {{IEEE} Transactions on Acoustics, Speech, and Signal Processing},
  year      = {1985},
  volume    = {33},
  number    = {2},
  pages     = {443--445},
  month     = {apr},
  doi       = {10.1109/tassp.1985.1164550},
  file      = {:Ephraim1985.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Book{Marr1982,
  title     = {Vision: A Computational Investigation into the Human Representation and Processing of Visual Information},
  publisher = {Henry Holt and Co., Inc.},
  year      = {1982},
  author    = {Marr, David},
  isbn      = {0716715678},
}

@InProceedings{Schmidt2006,
  author    = {Mikkel N. Schmidt and Rasmus Kongsgaard Olsson},
  title     = {Single-channel speech separation using sparse non-negative matrix factorization},
  booktitle = {Interspeech},
  year      = {2006},
  publisher = {{ISCA}},
  file      = {:/media/temporary/Downloads/7d8beae294dbd1fead2e9c613665f281d4a9.pdf:PDF},
}

@InProceedings{Tu2014,
  author    = {Yanhui Tu and Jun Du and Yong Xu and Lirong Dai and Chin-Hui Lee},
  title     = {Deep neural network based speech separation for robust speech recognition},
  booktitle = {12th IEEE International Conference on Signal Processing ({ICSP})},
  year      = {2014},
  month     = {oct},
  publisher = {{IEEE}},
  doi       = {10.1109/icosp.2014.7015061},
  file      = {:Tu2014.pdf:PDF},
}

@InProceedings{Arthur2007,
  author    = {Arthur, David and Vassilvitskii, Sergei},
  title     = {K-means++: The Advantages of Careful Seeding},
  booktitle = {Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  year      = {2007},
  series    = {SODA '07},
  pages     = {1027--1035},
  publisher = {Society for Industrial and Applied Mathematics},
  acmid     = {1283494},
  isbn      = {978-0-898716-24-5},
  location  = {New Orleans, Louisiana},
  numpages  = {9},
}

@Article{Lloyd1982,
  author    = {S. Lloyd},
  title     = {Least squares quantization in {PCM}},
  journal   = {{IEEE} Transactions on Information Theory},
  year      = {1982},
  volume    = {28},
  number    = {2},
  pages     = {129--137},
  month     = {mar},
  doi       = {10.1109/tit.1982.1056489},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@TechReport{Berkhin2002,
  author = {Pavel Berkhin},
  title  = {Survey Of Clustering Data Mining Techniques},
  year   = {2002},
}

@Article{Paliwal2011,
  author    = {Kuldip Paliwal and Kamil W{\'{o}}jcicki and Benjamin Shannon},
  title     = {The importance of phase in speech enhancement},
  journal   = {Speech Communication},
  year      = {2011},
  volume    = {53},
  number    = {4},
  pages     = {465--494},
  month     = {apr},
  doi       = {10.1016/j.specom.2010.12.003},
  publisher = {Elsevier {BV}},
}

@Article{Williamson2016,
  author    = {Donald S. Williamson and Yuxuan Wang and DeLiang Wang},
  title     = {Complex Ratio Masking for Monaural Speech Separation},
  journal   = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
  year      = {2016},
  volume    = {24},
  number    = {3},
  pages     = {483--492},
  month     = {mar},
  doi       = {10.1109/taslp.2015.2512042},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Book{Goodfellow2016,
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  file      = {:Goodfellow2016.pdf:PDF},
  url       = {http://www.deeplearningbook.org},
  urldate   = {2019-07-17},
}

@InProceedings{Maas2013,
  author    = {Maas, A.L. and Hannun, A.Y. and Ng, A.Y.},
  title     = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  year      = {2013},
}

@Book{Nielsen2015,
  title     = {Neural Networks and Deep Learning},
  publisher = {Determination Press},
  year      = {2015},
  author    = {Nielsen, M.A.},
  url       = {http://neuralnetworksanddeeplearning.com/},
  urldate   = {2019-07-17},
}

@Book{Graves2012,
  title     = {Supervised Sequence Labelling with Recurrent Neural Networks},
  publisher = {Springer},
  year      = {2012},
  author    = {Alex Graves},
  doi       = {10.1007/978-3-642-24797-2},
}

@Article{Schuster1997,
  author    = {M. Schuster and K.K. Paliwal},
  title     = {Bidirectional recurrent neural networks},
  journal   = {{IEEE} Transactions on Signal Processing},
  year      = {1997},
  volume    = {45},
  number    = {11},
  pages     = {2673--2681},
  doi       = {10.1109/78.650093},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Misc{Williams1995,
  author = {Ronald J. Williams and David Zipser},
  title  = {{Gradient-Based Learning Algorithms for Recurrent Networks and Their Computational Complexity}},
  year   = {1995},
}

@InProceedings{Heide1998,
  author    = {D. A. {Heide} and G. S. {Kang}},
  title     = {Speech enhancement for bandlimited speech},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {1998},
  volume    = {1},
  pages     = {393-396},
  month     = {May},
  doi       = {10.1109/ICASSP.1998.674450},
  keywords  = {speech enhancement;voice communication;speech intelligibility;military communication;vocoders;linear predictive coding;speech enhancement;bandlimited speech;tactical voice communication;voice terminal;passband;speech components;speech intelligibility;speech-processing technique;upperband speech components;Department of Defense standard mixed excitation linear predictor vocoder;MELP;0 to 8 kHz;2.4 kbit/s;Speech enhancement;Bandwidth;Low pass filters;Vocoders;Passband;History;Testing;Switching circuits;Telephony;Government},
}

@Article{Aloise2009,
  author    = {Daniel Aloise and Amit Deshpande and Pierre Hansen and Preyas Popat},
  title     = {{NP}-hardness of {E}uclidean sum-of-squares clustering},
  journal   = {Machine Learning},
  year      = {2009},
  volume    = {75},
  number    = {2},
  pages     = {245--248},
  month     = {jan},
  doi       = {10.1007/s10994-009-5103-0},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Kolbaek2017,
  author    = {Morten Kolbaek and Dong Yu and Zheng-Hua Tan and Jesper Jensen},
  title     = {Multitalker Speech Separation With Utterance-Level Permutation Invariant Training of Deep Recurrent Neural Networks},
  journal   = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
  year      = {2017},
  volume    = {25},
  number    = {10},
  pages     = {1901--1913},
  month     = {oct},
  doi       = {10.1109/taslp.2017.2726762},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Bauckhage2015,
  author        = {{Bauckhage}, Christian},
  title         = {{k-Means Clustering Is Matrix Factorization}},
  year          = {2015},
  month         = {Dec},
  archiveprefix = {arXiv},
  eprint        = {1512.07548},
  primaryclass  = {stat.ML},
}

@InCollection{Keogh2017,
  author    = {Eamonn Keogh and Abdullah Mueen},
  title     = {Curse of Dimensionality},
  booktitle = {Encyclopedia of Machine Learning and Data Mining},
  publisher = {Springer {US}},
  year      = {2017},
  pages     = {314--315},
  doi       = {10.1007/978-1-4899-7687-1_192},
}

@InCollection{Pudil1998,
  author    = {Pavel Pudil and Jana Novovi{\v{c}}ov{\'{a}}},
  title     = {Novel Methods for Feature Subset Selection with Respect to Problem Knowledge},
  booktitle = {Feature Extraction, Construction and Selection},
  publisher = {Springer},
  year      = {1998},
  pages     = {101--116},
  doi       = {10.1007/978-1-4615-5725-8_7},
}

@Article{Shlens2014,
  author        = {Jonathon Shlens},
  title         = {A Tutorial on Principal Component Analysis},
  year          = {2014},
  archiveprefix = {arXiv},
  eprint        = {1404.1100},
  primaryclass  = {cs.LG},
}

@Misc{Garofolo1993,
  author = {{Garofolo}, J.~S. and {Lamel}, L.~F. and {Fisher}, W.~M. and {Fiscus}, J.~G. and {Pallett}, D.~S.},
  title  = {{DARPA TIMIT - Acoustic-Phonetic Continuous Speech Corpus. NIST Speech Disc 1-1.1}},
  month  = feb,
  year   = {1993},
  volume = {93},
}

@Misc{Garofolo1994,
  author = {{Garofolo}, J.~S. and {Graff}, D.. and {Paul}, D. and {Pallett}, D.~S.},
  title  = {{ARPA CSR-WSJ0 - Continuous Speech Recognition Wall Street Journal. NIST Speech Discs 11-1.1 - 11-12.1, 11-13.1, 11-14.1, and 11-15.1}},
  month  = june,
  year   = {1994},
}

@InProceedings{Hernandez2018,
  author    = {Hernandez, Fran{\c{c}}ois and Nguyen, Vincent and Ghannay, Sahar and Tomashenko, Natalia and Est{\`e}ve, Yannick},
  title     = {TED-LIUM 3: Twice as Much Data and Corpus Repartition for Experiments on Speaker Adaptation},
  booktitle = {Speech and Computer},
  year      = {2018},
  editor    = {Karpov, Alexey and Jokisch, Oliver and Potapova, Rodmonga},
  pages     = {198--208},
  address   = {Cham},
  publisher = {Springer International Publishing},
  abstract  = {In this paper, we present TED-LIUM release 3 corpus (TED-LIUM 3 is available on https://lium.univ-lemans.fr/ted-lium3/) dedicated to speech recognition in English, which multiplies the available data to train acoustic models in comparison with TED-LIUM 2, by a factor of more than two. We present the recent development on Automatic Speech Recognition (ASR) systems in comparison with the two previous releases of the TED-LIUM Corpus from 2012 and 2014. We demonstrate that, passing from 207 to 452 h of transcribed speech training data is really more useful for end-to-end ASR systems than for HMM-based state-of-the-art ones. This is the case even if the HMM-based ASR system still outperforms the end-to-end ASR system when the size of audio training data is 452 h, with a Word Error Rate (WER) of 6.7{\%} and 13.7{\%}, respectively. Finally, we propose two repartitions of the TED-LIUM release 3 corpus: the legacy repartition that is the same as that existing in release 2, and a new repartition, calibrated and designed to make experiments on speaker adaptation. Similar to the two first releases, TED-LIUM 3 corpus will be freely available for the research community.},
  doi       = {10.1007/978-3-319-99579-3_21},
  isbn      = {978-3-319-99579-3},
}

@Article{Rafii2018,
  author    = {Zafar Rafii and Antoine Liutkus and Fabian-Robert Stoter and Stylianos Ioannis Mimilakis and Derry FitzGerald and Bryan Pardo},
  title     = {An Overview of Lead and Accompaniment Separation in Music},
  journal   = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
  year      = {2018},
  volume    = {26},
  number    = {8},
  pages     = {1307--1335},
  month     = {aug},
  doi       = {10.1109/taslp.2018.2825440},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Book{Kreyszig2006,
  title     = {Advanced Engineering Mathematics},
  publisher = {Wiley},
  year      = {2006},
  author    = {Kreyszig, E.},
  edition   = {9},
  isbn      = {978-0-471-72897-9},
}

@Misc{Sharpe2018,
  author  = {Bruce Sharpe},
  title   = {Invertibility of overlap-add processing},
  year    = {2018},
  url     = {https://gauss256.github.io/blog/cola.html},
  urldate = {2019-07-23},
}

@Article{Griffin1984,
  author    = {D. Griffin and Jae Lim},
  title     = {Signal estimation from modified short-time Fourier transform},
  journal   = {{IEEE} Transactions on Acoustics, Speech, and Signal Processing},
  year      = {1984},
  volume    = {32},
  number    = {2},
  pages     = {236--243},
  month     = {apr},
  doi       = {10.1109/tassp.1984.1164317},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Misc{McFee2019,
  author    = {McFee, Brian and McVicar, Matt and Balke, Stefan and Lostanlen, Vincent and Thomé, Carl and Raffel, Colin and Lee, Dana and {Kyungyun Lee} and Nieto, Oriol and Zalkow, Frank and Ellis, Dan and Battenberg, Eric and Yamamoto, Ryuichi and Moore, Josh and {Ziyao Wei} and Bittner, Rachel and {Keunwoo Choi} and {Nullmightybofo} and Friesch, Pius and {Fabian-Robert Stöter} and {, Thassilo} and Vollrath, Matt and {Siddhartha Kumar Golu} and {Nehz} and Waloschek, Simon and {, Seth} and Naktinis, Rimvydas and Repetto, Douglas and Hawthorne, Curtis and {CJ Carr}},
  title     = {librosa/librosa: 0.6.3},
  year      = {2019},
  doi       = {10.5281/zenodo.2564164},
  publisher = {Zenodo},
}

@Article{Greff2017,
  author    = {Klaus Greff and Rupesh K. Srivastava and Jan Koutnik and Bas R. Steunebrink and Jurgen Schmidhuber},
  title     = {{LSTM}: A Search Space Odyssey},
  journal   = {{IEEE} Transactions on Neural Networks and Learning Systems},
  year      = {2017},
  volume    = {28},
  number    = {10},
  pages     = {2222--2232},
  month     = {oct},
  doi       = {10.1109/tnnls.2016.2582924},
  file      = {:Greff2017.pdf:PDF},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Kingma2014,
  author        = {{Kingma}, Diederik P. and {Ba}, Jimmy},
  title         = {{Adam: A Method for Stochastic Optimization}},
  journal       = {arXiv e-prints},
  year          = {2014},
  pages         = {arXiv:1412.6980},
  month         = {Dec},
  archiveprefix = {arXiv},
  eid           = {arXiv:1412.6980},
  eprint        = {1412.6980},
  keywords      = {Computer Science - Machine Learning},
  primaryclass  = {cs.LG},
}

@Misc{PSF,
  author  = {{Python Software Foundation}},
  title   = {The Python Language Reference, version 3.7.3},
  url     = {https://docs.python.org/3/reference/},
  urldate = {2019-07-24},
}

@Article{Pedregosa2011,
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  title   = {Scikit-learn: Machine Learning in {P}ython},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  pages   = {2825--2830},
}

@Article{Hunter2007,
  author    = {John D. Hunter},
  title     = {Matplotlib: A 2D Graphics Environment},
  journal   = {Computing in Science {\&} Engineering},
  year      = {2007},
  volume    = {9},
  number    = {3},
  pages     = {90--95},
  doi       = {10.1109/mcse.2007.55},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Raffel2014,
  author        = {Colin Raffel and Brian McFee and Eric J. Humphrey and Justin Salamon and Oriol Nieto and Dawen Liang and Daniel P. W. Ellis},
  title         = {{mir\_eval: A Transparent Implementation of Common MIR Metrics}},
  journal       = {Proceedings of the 15th International Conference on Music Information Retrieval},
  year          = {2014},
  __markedentry = {[max:6]},
}

@TechReport{Fevotte2005,
  author   = {F{\'e}votte, C{\'e}dric and Gribonval, R{\'e}mi and Vincent, Emmanuel},
  title    = {{BSS\_EVAL Toolbox User Guide -- Revision 2.0}},
  year     = {2005},
  type     = {Technical Report},
  file     = {PI-1706.pdf:https\://hal.inria.fr/inria-00564760/file/PI-1706.pdf:PDF},
  keywords = {bss evaluation},
  pages    = {19},
  url      = {https://hal.inria.fr/inria-00564760},
}

@InProceedings{Abadi2016,
  author    = {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
  title     = {TensorFlow: A system for large-scale machine learning},
  booktitle = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
  year      = {2016},
  pages     = {265--283},
  url       = {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
}

@Article{Vincent2012,
  author    = {Emmanuel Vincent and Shoko Araki and Fabian Theis and Guido Nolte and Pau Bofill and Hiroshi Sawada and Alexey Ozerov and Vikrham Gowreesunker and Dominik Lutter and Ngoc Duong},
  title     = {{The Signal Separation Evaluation Campaign (2007{\textendash}2010): Achievements and Remaining Challenges}},
  journal   = {Signal Processing},
  year      = {2012},
  volume    = {92},
  number    = {8},
  pages     = {1928--1936},
  month     = {aug},
  doi       = {10.1016/j.sigpro.2011.10.007},
  publisher = {Elsevier {BV}},
}

@InProceedings{Vincent2007,
  author    = {Vincent, Emmanuel and Sawada, Hiroshi and Bofill, Pau and Makino, Shoji and Rosca, Justinian P.},
  title     = {{First Stereo Audio Source Separation Evaluation Campaign: Data, Algorithms and Results}},
  booktitle = {Independent Component Analysis and Signal Separation},
  year      = {2007},
  editor    = {Davies, Mike E. and James, Christopher J. and Abdallah, Samer A. and Plumbley, Mark D.},
  pages     = {552--559},
  publisher = {Springer},
  abstract  = {This article provides an overview of the first stereo audio source separation evaluation campaign, organized by the authors. Fifteen underdetermined stereo source separation algorithms have been applied to various audio data, including instantaneous, convolutive and real mixtures of speech or music sources. The data and the algorithms are presented and the estimated source signals are compared to reference signals using several objective performance criteria.},
  isbn      = {978-3-540-74494-8},
}

@InProceedings{Taal2010,
  author    = {Cees H. Taal and Richard C. Hendriks and Richard Heusdens and Jesper Jensen},
  title     = {A short-time objective intelligibility measure for time-frequency weighted noisy speech},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2010},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp.2010.5495701},
}

@InProceedings{Rix2001,
  author    = {A.W. Rix and J.G. Beerends and M.P. Hollier and A.P. Hekstra},
  title     = {Perceptual evaluation of speech quality ({PESQ})-a new method for speech quality assessment of telephone networks and codecs},
  booktitle = {IEEE International Conferenceon Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2001},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp.2001.941023},
}

@Article{Chung2014,
  author        = {Junyoung Chung and {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and KyungHyun Cho and Yoshua Bengio},
  title         = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
  year          = {2014},
  month         = {Dec},
  archiveprefix = {arXiv},
  eprint        = {1412.3555},
  primaryclass  = {cs.NE},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: fileDirectory:paper;}
